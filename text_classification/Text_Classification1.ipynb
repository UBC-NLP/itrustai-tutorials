{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Classification1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEXWrddpGUAF"
      },
      "source": [
        "# Text Classification \n",
        "\n",
        "## What is text Classification?\n",
        "\n",
        "Text classification (or document classification) is a basic problem in information science and computer science. It aims to assign a given text to one or more categories. We can find a wide range of real-world applications of text classification, such as spam filtering and sentiment analysis. As the following example shows, emails are categorized into two classes (i.e., spam and non-spam) by a classifier. The goal of Natural Language Processing (NLP) is to train a machine learning model on unlabelled or labelled data to create a classifier. The learning of text classification is formulated as:\n",
        "\n",
        "$$y = f(X)$$, where $X$ is the input samples, $y$ is the correponding labels of input samples, and $f()$ is a classifier. \n",
        " \n",
        "![](https://developers.google.com/machine-learning/guides/text-classification/images/TextClassificationExample.png)\n",
        "\n",
        "Picture Courtesy: https://developers.google.com/machine-learning/guides/text-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2gC-4zYShqS"
      },
      "source": [
        "## Supervised Text Classification with Classical Machine Learning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EibQFx_hWVP7"
      },
      "source": [
        "In this tutorial, we use the corpus from the [CL-Aff shared task](https://sites.google.com/view/affcon2019/cl-aff-shared-task?authuser=0). HappyDB is a dataset of about 100,000 `happy moments` crowd-sourced via Amazonâ€™s Mechanical Turk where each worker was asked to describe in a complete sentence `what made them happy in the past 24 hours`. Each user was asked to describe three such moments. \n",
        "\n",
        "In this tutorial, we focus on `sociality classification`. Sociality refers to `whether or not other people than the author are involved in the emotion situation`. For example, an emotion experience with a sociality value \"yes\" (i.e., other people are involved) could teach us about social groups (e.g., families) and the range of emotions expressed during specific types of situations (e.g., wedding, death). \n",
        "\n",
        "We only use labelled dataset which include 10,560 labelled samples. \n",
        "\n",
        "We placed the dataset under ``./happy_db`` folder in three files as ``train.tsv``, ``dev.tsv`` and ``test.tsv``. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGwUxablGS1A"
      },
      "source": [
        "#load package\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "import json\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZSLlZwxb98R"
      },
      "source": [
        "#### a. Load data sets: \n",
        "\n",
        "Files are tsv files whose delimiter is tab (i.e., \"\\t\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPDkfDxuVQ-m"
      },
      "source": [
        "train_set = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/happy_db/train.tsv\", sep=\"\\t\")\n",
        "dev_set = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/happy_db/dev.tsv\", sep=\"\\t\")\n",
        "test_set = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/happy_db/test.tsv\", sep=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "lLLZYVAZdDAM",
        "outputId": "ed2afb71-fa89-4139-e2b8-54fe1f719e0d"
      },
      "source": [
        "train_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>moment</th>\n",
              "      <th>social</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It was my birthday, and my wife and daughter s...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The weather has been warm and gorgeous for the...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yesterday, my boyfriend and I went to a beauti...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I bought a new cell phone for my dad.</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I got news from my supervisor that my request ...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              moment social\n",
              "0  It was my birthday, and my wife and daughter s...    yes\n",
              "1  The weather has been warm and gorgeous for the...     no\n",
              "2  Yesterday, my boyfriend and I went to a beauti...    yes\n",
              "3              I bought a new cell phone for my dad.    yes\n",
              "4  I got news from my supervisor that my request ...    yes"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjNLJ1KzcXOg"
      },
      "source": [
        "To train a machine learning system, we need to convert the text labels to numerical representations. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XP-1GZyVlNT"
      },
      "source": [
        "# convert textual label to numerical label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtuERdmQVnmF"
      },
      "source": [
        "label2ind = {'no': 0, 'yes': 1}\n",
        "\n",
        "train_set[\"social\"] = train_set[\"social\"].apply(lambda x: label2ind[x])\n",
        "dev_set[\"social\"] = dev_set[\"social\"].apply(lambda x: label2ind[x])\n",
        "test_set[\"social\"] = test_set[\"social\"].apply(lambda x: label2ind[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Q-Z5HVg5dM54",
        "outputId": "ce1180b0-eef1-4dab-a611-eacea2070ad6"
      },
      "source": [
        "train_set.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>moment</th>\n",
              "      <th>social</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It was my birthday, and my wife and daughter s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The weather has been warm and gorgeous for the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yesterday, my boyfriend and I went to a beauti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I bought a new cell phone for my dad.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I got news from my supervisor that my request ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              moment  social\n",
              "0  It was my birthday, and my wife and daughter s...       1\n",
              "1  The weather has been warm and gorgeous for the...       0\n",
              "2  Yesterday, my boyfriend and I went to a beauti...       1\n",
              "3              I bought a new cell phone for my dad.       1\n",
              "4  I got news from my supervisor that my request ...       1"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LjJogxEfKEZ"
      },
      "source": [
        "#### b. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz2nCzRYe6LM"
      },
      "source": [
        "X_train = train_set['moment']\n",
        "y_train = train_set['social']\n",
        "\n",
        "X_dev = dev_set['moment']\n",
        "y_dev = dev_set['social']\n",
        "\n",
        "X_test = test_set['moment']\n",
        "y_test = test_set['social']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al3JbIT8ly85"
      },
      "source": [
        "##### b.1 Normalize input texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMBzpjB-jLGq"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "\n",
        "def cleanHtml(sentence):\n",
        "  # function to remove url links\n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
        "    return cleantext\n",
        "def cleanPunc(sentence): \n",
        "  #function to remove punctuations or special characters\n",
        "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
        "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
        "    cleaned = cleaned.strip()\n",
        "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
        "    return cleaned\n",
        "\n",
        "def preprocessing(X):\n",
        "    X = X.str.lower() # lower case \n",
        "    X = X.apply(cleanHtml)\n",
        "    X = X.apply(cleanPunc)\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAqSCQpuluee"
      },
      "source": [
        "# apply preprocessing funtion\n",
        "X_train = preprocessing(X_train)\n",
        "X_dev = preprocessing(X_dev)\n",
        "X_test = preprocessing(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WDSm_gsoZdU",
        "outputId": "df9c8f09-32cd-46ce-e307-5af4f434f3b7"
      },
      "source": [
        "print(X_train[0])\n",
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "it was my birthday  and my wife and daughter surprised me with some surprise guests and a small party\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ROZTlFdmbPZ"
      },
      "source": [
        "##### b.2 Vectorization. \n",
        "\n",
        "We convert input text strings to a numerical vector. We use a `CountVectorizer` from sklearn to process input text. First, the vectorizer learns $n$-gram vocabulary from `X_train`. In this turorial, we use $uni$-gram only. Then, the vectorizer is applied to input texts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KveMgtUmLcJ",
        "outputId": "db692c42-794f-4cf3-a349-926a44bbcac2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer( analyzer='word', ngram_range=(1,1))\n",
        "vectorizer.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxEtznxKo6B8",
        "outputId": "efea7152-05fd-418e-d4ad-e63ccec32447"
      },
      "source": [
        "print( \"Vocabulary size: \", len(vectorizer.get_feature_names()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size:  6780\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7f9CuNbqioi"
      },
      "source": [
        "The vectorizer includes 6,780 words. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txr0vZGbmMuQ"
      },
      "source": [
        "# Processing input texts\n",
        "# Transform and save to a numpy array\n",
        "X_vec_train = vectorizer.transform(X_train).toarray() \n",
        "X_vec_dev = vectorizer.transform(X_dev).toarray() \n",
        "X_vec_test = vectorizer.transform(X_test).toarray() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEfI-Hjgq_nb"
      },
      "source": [
        "The `CountVectorizer` converts each text sample to a vocabulary-sized (i.e., 6,780) vecotor, $v=[v_1, ..., v_i], i \\in 1, ..., 6,780$. The value of $v_i$ is the counts of word $i$ in the given input text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqjkB8KVoPuN",
        "outputId": "ae812ff8-5a54-4244-c07c-1fbeaf97cf46"
      },
      "source": [
        "print(X_vec_train[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6780,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lx6aPxbMswUx"
      },
      "source": [
        "### Modeling "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6hwf8VQoRwS"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import classification_report,multilabel_confusion_matrix\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udD4lzoeA5ah"
      },
      "source": [
        "#### a. Gaussian Naive Bayes\n",
        "\n",
        "We utilize the inplementation from sklearn, [`sklearn.naive_bayes.GaussianNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html). The likelihood of the features is assumed to be Gaussian.\n",
        "<!-- The likelihood of the features is assumed to be Gaussian:\n",
        "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$ -->\n",
        "\n",
        "We use train a GaussianNB on training set and then evaluate on Dev and Test set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6qDMSHCs6jl",
        "outputId": "90b2563e-fb6f-41d4-a24f-880dbf09d123"
      },
      "source": [
        "# use training set to fit model \n",
        "classfier_gnb = GaussianNB()\n",
        "classfier_gnb.fit(X_vec_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afJxcQTxCnPF"
      },
      "source": [
        "# Use trained model to predict labels of Dev and Test sets and evaluate the predictions. \n",
        "\n",
        "pred_dev = classfier_gnb.predict(X_vec_dev)\n",
        "pred_test = classfier_gnb.predict(X_vec_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxONbG10FF5b"
      },
      "source": [
        "# Performance on Dev set\n",
        "acc_dev = accuracy_score(y_dev, pred_dev)\n",
        "f1_macro_dev = f1_score(y_dev, pred_dev, average=\"macro\")\n",
        "\n",
        "print(\"Performance on Dev set: f1_macro\",f1_macro_dev, \"Accuracy\", acc_dev)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d4VijHcFnIC",
        "outputId": "03b791b8-571f-4123-c2fc-442af86c757b"
      },
      "source": [
        "# Performance on Test set\n",
        "acc_test = accuracy_score(y_test, pred_test)\n",
        "f1_macro_test = f1_score(y_test, pred_test, average=\"macro\")\n",
        "\n",
        "print(\"Performance on Test set: f1_macro\", f1_macro_test, \"Accuracy\", acc_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance on Test set: f1_macro 0.7301075857022306 Accuracy 0.7301136363636364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-ZvGJB0GrhI"
      },
      "source": [
        "b. Logistic Regression\n",
        "\n",
        "We utilize the inplementation from sklearn, [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Logistic regression is a linear model for classification. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alhtAPfFGX-C",
        "outputId": "4c875a9b-7e46-4dc2-d207-c7095cf2e749"
      },
      "source": [
        "# use training set to fit model \n",
        "classfier_lr = LogisticRegression()\n",
        "classfier_lr.fit(X_vec_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqmvzxLEHKHg"
      },
      "source": [
        "# Use trained model to predict labels of Dev and Test sets and evaluate the predictions. \n",
        "\n",
        "pred_dev = classfier_lr.predict(X_vec_dev)\n",
        "pred_test = classfier_lr.predict(X_vec_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2tGYUzYHEIh",
        "outputId": "ff8db65a-4a32-466c-d9fe-6588ad30b581"
      },
      "source": [
        "# Performance on Dev set\n",
        "acc_dev = accuracy_score(y_dev, pred_dev)\n",
        "f1_macro_dev = f1_score(y_dev, pred_dev, average=\"macro\")\n",
        "\n",
        "print(\"Performance on Dev set: f1_macro\", f1_macro_dev, \"Accuracy\", acc_dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance on Dev set: f1_macro 0.8880262249827466 Accuracy 0.8882575757575758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9doC2w5HPHf",
        "outputId": "e65fac38-4f87-47fa-f1dd-a7da212c572d"
      },
      "source": [
        "# Performance on Test set\n",
        "acc_test = accuracy_score(y_test, pred_test)\n",
        "f1_macro_test = f1_score(y_test, pred_test, average=\"macro\")\n",
        "\n",
        "print(\"Performance on Test set: f1_macro\", f1_macro_test, \"Accuracy\", acc_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performance on Test set: f1_macro 0.887735685867497 Accuracy 0.8882575757575758\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RulB3Ae5ItvC"
      },
      "source": [
        "### References: \n",
        "* scikit-learn: https://scikit-learn.org/stable/ind\n",
        "* https://developers.google.com/machine-learning/guides/text-classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q07Hiq08I5wj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}