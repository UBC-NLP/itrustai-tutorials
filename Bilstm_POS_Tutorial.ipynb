{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2708fb6",
   "metadata": {},
   "source": [
    "# What is POS Tagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120a55ef",
   "metadata": {},
   "source": [
    "Part of Speech (POS) Tagging is a classification task that involves automatically assigning descriptions to tokens. The descriptor, called a tag, represents the part-of-speech of the word it is assigned to.\n",
    "\n",
    "In this tutorial, you will learn how to build your own POS tagger. We will be implementing a bi-directional LSTM (BiLSTM) to predict POS tags. We will use the Universal Dependencies English Web Treebank (UDPOS) dataset. You can check more information for UDPOS here: https://pytorch.org/text/stable/_modules/torchtext/datasets/udpos.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ba1f51",
   "metadata": {},
   "source": [
    "## What you will need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5cd51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy import datasets\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83190ef1",
   "metadata": {},
   "source": [
    "Completely reproducible results are not guaranteed across PyTorch releases, individual commits, or different platforms. Furthermore, results may not be reproducible between CPU and GPU executions, even when using identical seeds.\n",
    "\n",
    "However, there are some steps you can take to limit the number of sources of nondeterministic behavior for a specific platform, device, and PyTorch release. First, you can control sources of randomness that can cause multiple executions of your application to behave differently. Second, you can configure PyTorch to avoid using nondeterministic algorithms for some operations, so that multiple calls to those operations, given the same inputs, will produce the same result.\n",
    "\n",
    "We will use torch.manual_seed() to seed the RNG for all devices (both CPU and CUDA) and python's random seed. We will also use a deterministic implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f62c183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6255089",
   "metadata": {},
   "source": [
    "TorchText Field how your dataset is processed. The TEXT field handles how the text that we need to tag is processed. We set lower = True to lowercase all of the text.\n",
    "\n",
    "Next we will define the Fields for the tags. UDPOS dataset has two different sets of tags namely: the universal dependency (UD) tags and Penn Treebank (PTB) tags. We will train our model with the PTB tags.\n",
    "\n",
    "TorchText Fields initialize a default unknown token <unk> which we remove by setting unk_token = None. We set unk_token = None because we do not want unk_token tags in our tag set when the model encounters words without tags. We want every word tagged only with the tags in the PTB tags.\n",
    "    \n",
    "You can find more information about field her: https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a8dc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower = True)\n",
    "UD_TAGS = data.Field(unk_token = None)\n",
    "PTB_TAGS = data.Field(unk_token = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6065c678",
   "metadata": {},
   "source": [
    "We define fields for both the UD_TAGS and PTB_TAGS which passes the fields to the dataset. To define one of the tags alone, we can tell torchtext not to load those items using \"NONE\" as in\n",
    "\n",
    "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67d84dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5a280",
   "metadata": {},
   "source": [
    "We will then use the fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58583749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb1ccff",
   "metadata": {},
   "source": [
    "We check the size of our train, valid and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b9fe4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d1a8b",
   "metadata": {},
   "source": [
    "We can also print different examples and specify the text or the tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1032137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.'], 'udtags': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], 'ptbtags': ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1025ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b0ca3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['udtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "790cd63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['ptbtags'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa52df",
   "metadata": {},
   "source": [
    "You should now construct your vocabulary from the training data by calling the build_vocab function for the approporiate fields. The vocabulary maps tokens to integers. We want some unknown tokens within our dataset in order to replicate how this model would be used in real life, so we set the min_freq to 2 which means only tokens that appear at least twice in the training set will be added to the vocabulary and the rest will be replaced by <unk> tokens.\n",
    "\n",
    "We also load the fast-text pre-trained token embeddings. Other pre-trained embeddings can be used and you can find examples here: https://pytorch.org/text/stable/_modules/torchtext/vocab.html\n",
    "    \n",
    "unk_init is used to initialize the token embeddings which are not in the pre-trained embedding vocabulary. By default this sets those embeddings to zeros, however it is better to not have them all initialized to the same value, so we initialize them from a Normal/Gaussian distribution.\n",
    "\n",
    "These pre-trained vectors are now loaded into our vocabulary and we will initialize our model with these values later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39faf69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\wiki.simple.vec: 293MB [00:08, 36.6MB/s]                                                                                    \n",
      "  0%|                                                                                                          | 0/111051 [00:00<?, ?it/s]WARNING:torchtext.vocab:Skipping token b'111051' with 1-dimensional vector [b'300']; likely a header\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 111051/111051 [00:10<00:00, 10467.09it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ,\n",
    "                 vectors = \"fasttext.simple.300d\",\n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "\n",
    "UD_TAGS.build_vocab(train_data)\n",
    "PTB_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fed843",
   "metadata": {},
   "source": [
    "We can check how many tokens and tags are in our vocabulary by getting their length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9eff1dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 8866\n",
      "Unique tokens in UD_TAG vocabulary: 18\n",
      "Unique tokens in PTB_TAG vocabulary: 51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in UD_TAG vocabulary: {len(UD_TAGS.vocab)}\")\n",
    "print(f\"Unique tokens in PTB_TAG vocabulary: {len(PTB_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916616e",
   "metadata": {},
   "source": [
    "We can check the 10 most common tokens within our texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2e996fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 9076), ('.', 8640), (',', 7021), ('to', 5137), ('and', 5002), ('a', 3782), ('of', 3622), ('i', 3379), ('in', 3112), ('is', 2239)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f6698",
   "metadata": {},
   "source": [
    "We can check the tags in our vocabularies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c130e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'NOUN', 'PUNCT', 'VERB', 'PRON', 'ADP', 'DET', 'PROPN', 'ADJ', 'AUX', 'ADV', 'CCONJ', 'PART', 'NUM', 'SCONJ', 'X', 'INTJ', 'SYM']\n"
     ]
    }
   ],
   "source": [
    "print(UD_TAGS.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3699316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'NN', 'IN', 'DT', 'NNP', 'PRP', 'JJ', 'RB', '.', 'VB', 'NNS', ',', 'CC', 'VBD', 'VBP', 'VBZ', 'CD', 'VBN', 'VBG', 'MD', 'TO', 'PRP$', '-RRB-', '-LRB-', 'WDT', 'WRB', ':', '``', \"''\", 'WP', 'RP', 'UH', 'POS', 'HYPH', 'JJR', 'NNPS', 'JJS', 'EX', 'NFP', 'GW', 'ADD', 'RBR', '$', 'PDT', 'RBS', 'SYM', 'LS', 'FW', 'AFX', 'WP$', 'XX']\n"
     ]
    }
   ],
   "source": [
    "print(PTB_TAGS.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad11cfa",
   "metadata": {},
   "source": [
    "The UD_TAGS and the PTB_TAGS are different. We can check which tags are most common in our vocabulary. \n",
    "\n",
    "To check the frequencies of all tags in our vocabulary, we do not specify any number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a69e7347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 34781), ('PUNCT', 23679), ('VERB', 23081), ('PRON', 18577), ('ADP', 17638), ('DET', 16285), ('PROPN', 12946), ('ADJ', 12477), ('AUX', 12343), ('ADV', 10548), ('CCONJ', 6707), ('PART', 5567), ('NUM', 3999), ('SCONJ', 3843), ('X', 847), ('INTJ', 688), ('SYM', 599)]\n"
     ]
    }
   ],
   "source": [
    "print(UD_TAGS.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e4640ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NN', 26915), ('IN', 20724), ('DT', 16817), ('NNP', 12449), ('PRP', 12193), ('JJ', 11591), ('RB', 10831), ('.', 10317), ('VB', 9476), ('NNS', 8438), (',', 8062), ('CC', 6706), ('VBD', 5402), ('VBP', 5374), ('VBZ', 4578), ('CD', 3998), ('VBN', 3967), ('VBG', 3330), ('MD', 3294), ('TO', 3286), ('PRP$', 3068), ('-RRB-', 1008), ('-LRB-', 973), ('WDT', 948), ('WRB', 869), (':', 866), ('``', 813), (\"''\", 785), ('WP', 760), ('RP', 755), ('UH', 689), ('POS', 684), ('HYPH', 664), ('JJR', 503), ('NNPS', 498), ('JJS', 383), ('EX', 359), ('NFP', 338), ('GW', 294), ('ADD', 292), ('RBR', 276), ('$', 258), ('PDT', 175), ('RBS', 169), ('SYM', 156), ('LS', 117), ('FW', 93), ('AFX', 48), ('WP$', 15), ('XX', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(PTB_TAGS.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab782a93",
   "metadata": {},
   "source": [
    "Finally we create iterators. The iterators takes the vocabulary in batches we define. We used a bucket iterator. Details are here: https://torchtext.readthedocs.io/en/latest/data.html#iterator \n",
    "\n",
    "The bucket iterator https://torchtext.readthedocs.io/en/latest/data.html#bucketiterator defines an iterator that batches examples of similar lengths together which minimizes the amount of padding needed while producing freshly shuffled batches for each new epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e024c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "attachments": {
    "image-3.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "cedf9b82",
   "metadata": {},
   "source": [
    "We define a multi-layer bi-directional LSTM. The image below shows a simplified version of the model with only one LSTM layer and omitting the LSTM's cell state for clarity.\n",
    "\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "The model takes in a sequence of tokens,  in this case w1 ... wn which are represented as embeddings and passes them to the forward and backward LSTMs. The forward LSTM processes the sequence from left-to-right, whilst the backward LSTM processes the sequence right-to-left, i.e. the first input to the forward LSTM is  w1  and the first input to the backward LSTM is  wn.\n",
    "\n",
    "After the whole sequence has been processed, the hidden and cell states are then passed to the next layer of the LSTM in a multidimensional LSTM as we will use.\n",
    "\n",
    "When training the model, we will compare our predicted tags,  Y^  against the actual tags,  Y , to calculate a loss, the gradients w.r.t. that loss, and then update our parameters.\n",
    "\n",
    "We implement the BILSTM model above in the BiLSTMPOSTagger class.\n",
    "\n",
    "nn.Embedding is an embedding layer and the input dimension should be the size of the input (text) vocabulary. We tell it what the index of the padding token is so it does not update the padding token's embedding entry.\n",
    "\n",
    "nn.LSTM is the LSTM. We apply dropout as regularization between the layers, if we are using more than one.\n",
    "\n",
    "nn.Linear defines the linear layer to make predictions using the LSTM outputs. We double the size of the input if we are using a bi-directional LSTM. The output dimensions should be the size of the tag vocabulary.\n",
    "\n",
    "We also define a dropout layer with nn.Dropout, which we use in the forward method to apply dropout to the embeddings and the outputs of the final layer of the LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4516226",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 embedding_dim, \n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout, \n",
    "                 pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout if n_layers > 1 else 0)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        #pass text through embedding layer\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        #pass embeddings into LSTM\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        #outputs holds the backward and forward hidden states in the final layer\n",
    "        #hidden and cell are the backward and forward hidden and cell states at the final time-step\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        #we use our outputs to make a prediction of what the tag should be\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025cc8b",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1f833",
   "metadata": {},
   "source": [
    "We instantiate the BiLSTMPOSTagger model. We need to ensure the embedding dimensions is the same size as that of the embeddings we loaded. \n",
    "\n",
    "The other values are hyperparameters and different combinations of values can improve or worsen the models. They therefore need to be chosen carefully. The input and output dimensions are taken directly from the lengths of the respective vocabularies. The padding index is obtained using the vocabulary and the Field of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b3f6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(PTB_TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = BiLSTMPOSTagger(INPUT_DIM, \n",
    "                        EMBEDDING_DIM, \n",
    "                        HIDDEN_DIM, \n",
    "                        OUTPUT_DIM, \n",
    "                        N_LAYERS, \n",
    "                        BIDIRECTIONAL, \n",
    "                        DROPOUT, \n",
    "                        PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb4064",
   "metadata": {},
   "source": [
    "We initialize the weights from a simple Normal distribution. This is also a hyperparameter and different values may be better for this model and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5af2ead9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMPOSTagger(\n",
       "  (embedding): Embedding(8866, 300, padding_idx=1)\n",
       "  (lstm): LSTM(300, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91c8300",
   "metadata": {},
   "source": [
    "We will initialize our model's embedding layer with the pre-trained embedding values we loaded earlier.\n",
    "\n",
    "This is done by getting them from the vocab's vectors attribute and then performing a copy to overwrite the embedding layer's current weights.\n",
    "\n",
    "We also initialize the embedding of the pad token to all zeros. This, along with setting the padding_idx in the model's embedding layer, means that the embedding should always output a tensor full of zeros when a pad token is input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3383718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8866, 300])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1f3e6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2213, -0.2354, -0.4294,  ..., -1.4476, -0.4606, -0.7150],\n",
       "        [-0.8855,  1.6317, -0.2035,  ...,  2.3360, -1.5412,  2.7414],\n",
       "        [ 0.0104, -0.1829,  0.0761,  ..., -0.1362, -0.2240, -0.0552],\n",
       "        ...,\n",
       "        [-1.9967,  1.1004,  1.1619,  ...,  0.9477, -0.4274, -2.3395],\n",
       "        [-0.1719, -0.1336, -0.1457,  ...,  0.2113, -0.1002, -0.0555],\n",
       "        [-0.3669,  0.1386,  0.5516,  ..., -0.7994, -0.5704, -0.3140]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a9b36c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2213, -0.2354, -0.4294,  ..., -1.4476, -0.4606, -0.7150],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0104, -0.1829,  0.0761,  ..., -0.1362, -0.2240, -0.0552],\n",
      "        ...,\n",
      "        [-1.9967,  1.1004,  1.1619,  ...,  0.9477, -0.4274, -2.3395],\n",
      "        [-0.1719, -0.1336, -0.1457,  ...,  0.2113, -0.1002, -0.0555],\n",
      "        [-0.3669,  0.1386,  0.5516,  ..., -0.7994, -0.5704, -0.3140]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a507fe1",
   "metadata": {},
   "source": [
    "We then define our optimizer, used to update our parameters w.r.t. their gradients. We use Adam with the default learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "16fa39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10755f1",
   "metadata": {},
   "source": [
    "Next, we define our loss function, cross-entropy loss.\n",
    "\n",
    "Even though we have no <unk> tokens within our tag vocab, we still have <pad> tokens. This is because all sentences within a batch need to be the same size. However, we don't want to calculate the loss when the target is a <pad> token as we aren't training our model to recognize padding tokens.\n",
    "\n",
    "We handle this by setting the ignore_index in our loss function to the index of the padding token in our tag vocabulary.\n",
    "    \n",
    "We then place our model and loss function on our GPU, if we have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63979aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = PTB_TAGS.vocab.stoi[PTB_TAGS.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e42377f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7188c8f9",
   "metadata": {},
   "source": [
    "We will be using the loss value between our predicted and actual tags to train the network, but ideally we'd like a more interpretable way to see how well our model is doing - accuracy.\n",
    "\n",
    "The issue is that we don't want to calculate accuracy over the <pad> tokens as we aren't interested in predicting them.\n",
    "\n",
    "The function below only calculates accuracy over non-padded tokens. Non_pad_elements is a tensor containing the indices of the non-pad tokens within an input batch. We then compare the predictions of those elements with the labels to get a count of how many predictions were correct. We then divide this by the number of non-pad elements to get our accuracy value over the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81b2995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / y[non_pad_elements].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cc2477",
   "metadata": {},
   "source": [
    "We first set the model to train mode to turn on dropout/batch-norm/etc. (if used). Then we iterate over our iterator, which returns a batch of examples.\n",
    "\n",
    "For each batch:\n",
    "\n",
    "we zero the gradients over the parameters from the last gradient calculation\n",
    "insert the batch of text into the model to get predictions\n",
    "as PyTorch loss functions cannot handle 3-dimensional predictions we reshape our predictions\n",
    "calculate the loss and accuracy between the predicted tags and actual tags\n",
    "call backward to calculate the gradients of the parameters w.r.t. the loss\n",
    "take an optimizer step to update the parameters\n",
    "add to the running total of loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8bc22e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        text = batch.text\n",
    "        tags = batch.udtags\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        \n",
    "        predictions = model(text)\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        #tags = [sent len * batch size]\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80422da7",
   "metadata": {},
   "source": [
    "In the evaluate function, we don't update the model's parameters because we are only interested in comparing the actual tags with the predicted tags. We place the model in evaluation mode using model.eval()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c9d2582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.udtags\n",
    "            \n",
    "            predictions = model(text)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c17ff",
   "metadata": {},
   "source": [
    "Finally, we train our model!\n",
    "\n",
    "After each epoch we check if our model has achieved the best validation loss so far. If it has then we save the parameters of this model and we will use these \"best\" parameters to calculate performance over our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3ac8b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.248 | Train Acc: 61.59%\n",
      "\t Val. Loss: 0.530 |  Val. Acc: 83.89%\n",
      "\tTrain Loss: 0.326 | Train Acc: 89.84%\n",
      "\t Val. Loss: 0.413 |  Val. Acc: 88.20%\n",
      "\tTrain Loss: 0.243 | Train Acc: 92.29%\n",
      "\t Val. Loss: 0.385 |  Val. Acc: 88.90%\n",
      "\tTrain Loss: 0.203 | Train Acc: 93.47%\n",
      "\t Val. Loss: 0.375 |  Val. Acc: 89.33%\n",
      "\tTrain Loss: 0.176 | Train Acc: 94.29%\n",
      "\t Val. Loss: 0.364 |  Val. Acc: 89.72%\n",
      "\tTrain Loss: 0.156 | Train Acc: 94.91%\n",
      "\t Val. Loss: 0.358 |  Val. Acc: 90.07%\n",
      "\tTrain Loss: 0.139 | Train Acc: 95.49%\n",
      "\t Val. Loss: 0.354 |  Val. Acc: 90.03%\n",
      "\tTrain Loss: 0.126 | Train Acc: 95.89%\n",
      "\t Val. Loss: 0.372 |  Val. Acc: 90.06%\n",
      "\tTrain Loss: 0.114 | Train Acc: 96.31%\n",
      "\t Val. Loss: 0.372 |  Val. Acc: 90.18%\n",
      "\tTrain Loss: 0.103 | Train Acc: 96.63%\n",
      "\t Val. Loss: 0.371 |  Val. Acc: 90.22%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2583e8",
   "metadata": {},
   "source": [
    "We then load our \"best\" parameters and evaluate performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6868d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.369 |  Test Acc: 89.34%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut1-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bebdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
